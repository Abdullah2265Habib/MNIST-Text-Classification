{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f0416f-c9c4-4beb-832a-52ee782133be",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a861e6-2465-4d57-a306-722ff5ff9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577145c-7c75-4ea6-8fb7-4564300b4f18",
   "metadata": {},
   "source": [
    "# Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "169f231f-fb46-43ca-9eeb-b66786f1e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c34d3b-30b3-4161-9a1d-1f967871b226",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9c23e5-a89b-4378-a6fe-ba755009b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = Image.open(img_path).convert('L')         # Grayscale\n",
    "    img = ImageOps.invert(img)                      # Invert colors\n",
    "    img = img.resize((28, 28))                      # Resize to 28x28\n",
    "    img_array = np.array(img) / 255.0               # Normalize to [0, 1]\n",
    "    img_array = img_array.reshape(1, 784)           # Reshape for model input\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c2b92-8fed-45b3-aca5-6a4e3c3dba9b",
   "metadata": {},
   "source": [
    "# Image Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4940e368-3c8b-403f-a1d3-adb16f5b2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"test/image2/digit.png\"  # path to image\n",
    "x_input = preprocess_image(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf1890-d013-4267-bc9e-73978eed04bc",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400ebf0e-89d9-4638-885f-af8912d8522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000161A5301AB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000161A5301AB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Predicted Digit: 4\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_input)\n",
    "digit = np.argmax(pred)\n",
    "print(f\"Predicted Digit: {digit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c522c-619c-4354-ab54-ad6f226c45b8",
   "metadata": {},
   "source": [
    "# Show Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9ada15-4588-4b9c-a446-6c0370bb9d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_input.reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted: {digit}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
